vip_train
#| label: model-agnostic explainer: random forest model
explainer_rf <-
explain_tidymodels(
rf_fit,
data = vip_train,
y = ames_train$Sale_Price,
label = "random forest",
verbose = FALSE
)
explainer_rf
#| label: duplex building type in the North Ames neighborhood
duplex <- vip_train[120, ]
duplex
#| label: breakdown explanation implemented with predict_parts() for the linear model
lm_breakdown <- predict_parts(explainer = explainer_lm, new_observation = duplex)
lm_breakdown
#| label: breakdown explanation implemented with predict_parts() for the random forest model
rf_breakdown <- predict_parts(explainer = explainer_rf, new_observation = duplex)
rf_breakdown
#| label: changing the relative importance of the features
predict_parts(
explainer = explainer_rf,
new_observation = duplex,
order = lm_breakdown$variable_name
)
#| label: load necessary packages
library(DALEXtra)
#| label: define the features for model-agnostic explainer
vip_features <-
c("Neighborhood", "Gr_Liv_Area", "Year_Built", "Bldg_Type",
"Latitude", "Longitude")
vip_features
#| label: load necessary packages
library(dplyr)
#| label: extraxting vip features from training data
vip_train <-
ames_train |>
select(all_of(vip_features))
vip_train
#| label: model-agnostic explainer: random forest model
explainer_rf <-
explain_tidymodels(
rf_fit,
data = vip_train,
y = ames_train$Sale_Price,
label = "random forest",
verbose = FALSE
)
explainer_rf
#| label: duplex building type in the North Ames neighborhood
duplex <- vip_train[120, ]
duplex
#| label: breakdown explanation implemented with predict_parts() for the linear model
lm_breakdown <- predict_parts(explainer = explainer_lm, new_observation = duplex)
lm_breakdown
#| label: breakdown explanation implemented with predict_parts() for the random forest model
rf_breakdown <- predict_parts(explainer = explainer_rf, new_observation = duplex)
rf_breakdown
#| label: changing the relative importance of the features
predict_parts(
explainer = explainer_rf,
new_observation = duplex,
order = lm_breakdown$variable_name
)
#| label: load necessary packages
library(DALEXtra)
#| label: define the features for model-agnostic explainer
vip_features <-
c("Neighborhood", "Gr_Liv_Area", "Year_Built", "Bldg_Type",
"Latitude", "Longitude")
vip_features
#| label: load necessary packages
library(dplyr)
#| label: define the features for model-agnostic explainer
vip_features <-
c("Neighborhood", "Gr_Liv_Area", "Year_Built", "Bldg_Type",
"Latitude", "Longitude")
vip_features
#| label: load necessary packages
library(dplyr)
#| label: load necessary packages
library(dplyr)
#| label: extraxting vip features from training data
vip_train <-
ames_train |>
select(all_of(vip_features))
vip_train
#| label: model-agnostic explainer: random forest model
explainer_rf <-
explain_tidymodels(
rf_fit,
data = vip_train,
y = ames_train$Sale_Price,
label = "random forest",
verbose = FALSE
)
explainer_rf
#| label: duplex building type in the North Ames neighborhood
duplex <- vip_train[120, ]
duplex
#| label: breakdown explanation implemented with predict_parts() for the linear model
lm_breakdown <- predict_parts(explainer = explainer_lm, new_observation = duplex)
lm_breakdown
#| label: breakdown explanation implemented with predict_parts() for the random forest model
rf_breakdown <- predict_parts(explainer = explainer_rf, new_observation = duplex)
rf_breakdown
#| label: changing the relative importance of the features
predict_parts(
explainer = explainer_rf,
new_observation = duplex,
order = lm_breakdown$variable_name
)
#| label: Shaply Additive Explainations
set.seed(1801)
shap_duplex <-
predict_parts(
explainer = explainer_rf,
new_observation = duplex,
type = "shap",
B = 20
)
#| label: Shaply Additive Explainations
set.seed(1801)
shap_duplex <-
predict_parts(
explainer = explainer_rf,
new_observation = duplex,
type = "shap",
B = 20
)
shap_duplex
#| label: load necessary packages
library(forcats)
#| label: visualizing the distribution of contributions accross all the orderings (box plots) and the average attribution for each feature (bar plots)
shap_duplex |>
group_by(variable) |>
mutate(mean_val = mean(contribution)) |>
ungroup() |>
mutate(variable = fct_reorder(variable, abs(mean_val))) |>
ggplot(aes(contribution, variable, fill = mean_val > 0)) +
geom_col(data = -distinct(., variable, mean_val),
aes(mean_val, variable),
alpha = 0.5) +
geom_boxplot(width = 0.5) +
theme(legend.position = "none") +
scale_fill_viridis_d() +
labs(y = NULL)
#| label: visualizing the distribution of contributions accross all the orderings (box plots) and the average attribution for each feature (bar plots)
shap_duplex |>
group_by(variable) |>
mutate(mean_val = mean(contribution)) |>
ungroup() |>
mutate(variable = fct_reorder(variable, abs(mean_val))) |>
ggplot(aes(contribution, variable, fill = mean_val > 0)) +
geom_col(data = ~distinct(., variable, mean_val),
aes(mean_val, variable),
alpha = 0.5) +
geom_boxplot(width = 0.5) +
theme(legend.position = "none") +
scale_fill_viridis_d() +
labs(y = NULL)
#| label: load necessary packages
theme_set(theme_bw())
library(DALEXtra)
#| label: visualizing the distribution of contributions accross all the orderings (box plots) and the average attribution for each feature (bar plots)
shap_duplex |>
group_by(variable) |>
mutate(mean_val = mean(contribution)) |>
ungroup() |>
mutate(variable = fct_reorder(variable, abs(mean_val))) |>
ggplot(aes(contribution, variable, fill = mean_val > 0)) +
geom_col(data = ~distinct(., variable, mean_val),
aes(mean_val, variable),
alpha = 0.5) +
geom_boxplot(width = 0.5) +
theme(legend.position = "none") +
scale_fill_viridis_d() +
labs(y = NULL)
View(shap_duplex)
#| label: one-family home type in the Gilber neighborhood
big_house <- vip_train[1269, ]
big_house
#| label: Shaply Additive Explainations for the duplex type in the Gilbert neighborhood
set.seed(1802)
shap_house <-
predict_parts(
explainer = explainer_rf,
new_observation = big_house,
type = "shap",
B = 20
)
shap_house
shap_house |>
group_by(variable) |>
mutate(mean_val = mean(contribution)) |>
ungroup() |>
mutate(variable = fct_reorder(variable, abs(mean_val))) |>
ggplot(aes(contribution, variable, fill = mean_val > 0)) +
geom_col(data = ~distinct(., variable, mean_val),
aes(mean_val, variable),
alpha = 0.5) +
geom_boxplot(width = 0.5) +
theme(legend.position = "none") +
scale_fill_viridis_d() +
labs(y = NULL)
#| label: global explainations via model_parts function for the linear regression model
set.seed(1803)
vip_lm <- model_parts(explainer_lm, loss_function = loss_root_mean_square)
vip_lm
#| label: global explainations via model_parts function for the random forest model
set.seed(1804)
vip_rf <- model_parts(explainer_rf, loss_function = loss_root_mean_square)
vip_rf
#| label: defining a function for visualizing global explanations
ggplot_imp <- function(...) {
obj <- list(...)
metric_name <- attr(obj[[1]], "loss_name")
metric_lab <- paste(metric_name,
"after permutations\n()higher indicates more important")
full_vip <- bind_rows(obj) |>
filter(variable != "_baseline_")
perm_vals <- full_vip |>
filter(variable == "_full_model_") |>
group_by(label) |>
summarise(dropout_loss = mean(dropout_loss))
p <- full_vip |>
filter(variable != "_full_model_") |>
mutate(variable = fct_reorder(variable, dropout_loss)) |>
ggplot(aes(dropout_loss, variable))
if(length(obj) > 1) {
p <- p +
facet_wrap(vars(label)) +
geom_vline(data = perm_vals, aes(xintercept = dropout_loss, color = label),
linewidth = 1.4, lty = 2, alpha = 0.7) +
geom_boxplot(aes(color = label, fill = label), alpha = 0.2)
}
else {
p <- p +
geom_vline(data = perm_vals, aes(xintercept = dropout_loss),
linewidth = 1.4, lty = 2, alpha = 0.7) +
geom_boxplot(fill = "#91CBD765", alpha = 0.4)
}
p +
theme(legend.position = "none") +
labs(x = metric_lab,
y = NULL, fill = NULL, color = NULL
)
}
#| label: defining a function for visualizing global explanations
ggplot_imp <- function(...) {
obj <- list(...)
metric_name <- attr(obj[[1]], "loss_name")
metric_lab <- paste(metric_name,
"after permutations\n(higher indicates more important)")
full_vip <- bind_rows(obj) |>
filter(variable != "_baseline_")
perm_vals <- full_vip |>
filter(variable == "_full_model_") |>
group_by(label) |>
summarise(dropout_loss = mean(dropout_loss))
p <- full_vip |>
filter(variable != "_full_model_") |>
mutate(variable = fct_reorder(variable, dropout_loss)) |>
ggplot(aes(dropout_loss, variable))
if(length(obj) > 1) {
p <- p +
facet_wrap(vars(label)) +
geom_vline(data = perm_vals, aes(xintercept = dropout_loss, color = label),
linewidth = 1.4, lty = 2, alpha = 0.7) +
geom_boxplot(aes(color = label, fill = label), alpha = 0.2)
} else {
p <- p +
geom_vline(data = perm_vals, aes(xintercept = dropout_loss),
linewidth = 1.4, lty = 2, alpha = 0.7) +
geom_boxplot(fill = "#91CBD765", alpha = 0.4)
}
p +
theme(legend.position = "none") +
labs(x = metric_lab,
y = NULL, fill = NULL, color = NULL)
}
#| label: visualizing the global explanations using the defined function
ggplot_imp(vip_lm, vip_rf)
source("~/Desktop/tmwr/scripts/00-ames-housing-model-building.R")
#| label: load necessary packages
library(ggplot2)
theme_set(theme_bw())
library(DALEXtra)
#| label: define the features for model-agnostic explainer
vip_features <-
c("Neighborhood", "Gr_Liv_Area", "Year_Built", "Bldg_Type",
"Latitude", "Longitude")
vip_features
#| label: load necessary packages
library(dplyr)
#| label: extraxting vip features from training data
vip_train <-
ames_train |>
select(all_of(vip_features))
vip_train
#| label: model-agnostic explainer: linear regression model
explainer_lm <-
explain_tidymodels(
lm_fit,
data = vip_train,
y = ames_train$Sale_Price,
label = "lm + interactions",
verbose = FALSE
)
explainer_lm
#| label: model-agnostic explainer: random forest model
explainer_rf <-
explain_tidymodels(
rf_fit,
data = vip_train,
y = ames_train$Sale_Price,
label = "random forest",
verbose = FALSE
)
explainer_rf
#| label: duplex building type in the North Ames neighborhood
duplex <- vip_train[120, ]
duplex
#| label: breakdown explanation implemented with predict_parts() for the linear model
lm_breakdown <- predict_parts(explainer = explainer_lm, new_observation = duplex)
lm_breakdown
#| label: breakdown explanation implemented with predict_parts() for the random forest model
rf_breakdown <- predict_parts(explainer = explainer_rf, new_observation = duplex)
rf_breakdown
#| label: changing the relative importance of the features
predict_parts(
explainer = explainer_rf,
new_observation = duplex,
order = lm_breakdown$variable_name
)
#| label: Shaply Additive Explainations for the duplex type in the North Ames neighborhood
set.seed(1801)
shap_duplex <-
predict_parts(
explainer = explainer_rf,
new_observation = duplex,
type = "shap",
B = 20
)
shap_duplex
#| label: load necessary packages
library(forcats)
#| label: visualizing the distribution of contributions accross all the orderings (box plots) and the average attribution for each feature (bar plots) - a duplex property in the North Ames
shap_duplex |>
group_by(variable) |>
mutate(mean_val = mean(contribution)) |>
ungroup() |>
mutate(variable = fct_reorder(variable, abs(mean_val))) |>
ggplot(aes(contribution, variable, fill = mean_val > 0)) +
geom_col(data = ~distinct(., variable, mean_val),
aes(mean_val, variable),
alpha = 0.5) +
geom_boxplot(width = 0.5) +
theme(legend.position = "none") +
scale_fill_viridis_d() +
labs(y = NULL)
#| label: one-family home type in the Gilbert neighborhood
big_house <- vip_train[1269, ]
big_house
#| label: Shaply Additive Explainations for the duplex type in the Gilbert neighborhood
set.seed(1802)
shap_house <-
predict_parts(
explainer = explainer_rf,
new_observation = big_house,
type = "shap",
B = 20
)
shap_house
#| label: visualizing the distribution of contributions accross all the orderings (box plots) and the average attribution for each feature (bar plots) - a one-family home in Gilbert
shap_house |>
group_by(variable) |>
mutate(mean_val = mean(contribution)) |>
ungroup() |>
mutate(variable = fct_reorder(variable, abs(mean_val))) |>
ggplot(aes(contribution, variable, fill = mean_val > 0)) +
geom_col(data = ~distinct(., variable, mean_val),
aes(mean_val, variable),
alpha = 0.5) +
geom_boxplot(width = 0.5) +
theme(legend.position = "none") +
scale_fill_viridis_d() +
labs(y = NULL)
#| label: global explainations via model_parts function for the linear regression model
set.seed(1803)
vip_lm <- model_parts(explainer_lm, loss_function = loss_root_mean_square)
vip_lm
#| label: global explainations via model_parts function for the random forest model
set.seed(1804)
vip_rf <- model_parts(explainer_rf, loss_function = loss_root_mean_square)
vip_rf
#| label: defining a function for visualizing global explanations
ggplot_imp <- function(...) {
obj <- list(...)
metric_name <- attr(obj[[1]], "loss_name")
metric_lab <- paste(metric_name,
"after permutations\n(higher indicates more important)")
full_vip <- bind_rows(obj) |>
filter(variable != "_baseline_")
perm_vals <- full_vip |>
filter(variable == "_full_model_") |>
group_by(label) |>
summarise(dropout_loss = mean(dropout_loss))
p <- full_vip |>
filter(variable != "_full_model_") |>
mutate(variable = fct_reorder(variable, dropout_loss)) |>
ggplot(aes(dropout_loss, variable))
if(length(obj) > 1) {
p <- p +
facet_wrap(vars(label)) +
geom_vline(data = perm_vals, aes(xintercept = dropout_loss, color = label),
linewidth = 1.4, lty = 2, alpha = 0.7) +
geom_boxplot(aes(color = label, fill = label), alpha = 0.2)
} else {
p <- p +
geom_vline(data = perm_vals, aes(xintercept = dropout_loss),
linewidth = 1.4, lty = 2, alpha = 0.7) +
geom_boxplot(fill = "#91CBD765", alpha = 0.4)
}
p +
theme(legend.position = "none") +
labs(x = metric_lab,
y = NULL, fill = NULL, color = NULL)
}
#| label: visualizing the global explainer for the random forest and linear regression models via the defined function
ggplot_imp(vip_lm, vip_rf)
#| label: Partial Dependence Profile using age feature
set.seed(1805)
pdp_age <- model_profile(explainer_rf, N = 500, variables = "Year_Built")
pdp_age
#| label: defining a function to visualize a partial dependence profile
ggplot_pdp <- function(obj, x) {
p <-
as_tibble(obj$agr_profiles) |>
mutate(`_label_` = stringr::str_remove(`_label_`, "^[^_]*_")) |>
ggplot(aes(`_x_`, `_yhat_`)) +
geom_line(data = as_tibble(obj$cp_profiles),
aes(x = {{ x }}, group = `_ids_`),
linewidth = 0.5, alpha = 0.05, color = "gray50")
num_colors <- n_distinct(obj$agr_profiles$`_label_`)
if (num_colors > 1) {
p <- p + geom_line(aes(color = `_label_`), linewidth = 1.2, alpha = 0.8)
} else {
p <- p + geom_line(color = "midnightblue", linewidth = 1.2, alpha = 0.8)
}
p
}
#| label: visualizing a partial dependence profiles for the random forest model focusing on the year built predictor
ggplot_pdp(pdp_age, Year_Built) +
labs(x = "Year built",
y = "Sale Price (log)",
color = NULL)
#| label: Partial Dependence Profile using gross living area and groups of building types
set.seed(1806)
pdp_liv <- model_profile(explainer_rf, N = 10000,
variables = "Gr_Liv_Area",
groups = "Bldg_Type")
pdp_liv
#| label: visualizing Partial dependence profiles for the random forest model focusing on building types and gross living area
ggplot_pdp(pdp_liv, Gr_Liv_Area) +
scale_x_log10() +
scale_color_brewer(palette = "Dark2") +
labs(x = "Gross living area",
y = "Sale Price (log)",
color = NULL)
#| label: Partial dependence profiles for the random forest model focusing on building types and gross living area using facets
as_tibble(pdp_liv$agr_profiles) |>
mutate(Bldg_Type = stringr::str_remove(`_label_`, "random_forest_")) |>
ggplot(aes("_x_", "_yhat_", color = Bldg_Type)) +
geom_line(data = as_tibble(pdp_liv$cp_profiles),
aes(x = Gr_Liv_Area, group = `_ids_`),
linewidth = 0.5, alpha = 0.1, color = "gray50") +
geom_line(linewidth = 1.2, alpha = 0.8, show.legend = FALSE) +
scale_x_log10() +
facet_wrap(~Bldg_Type) +
scale_color_brewer(palette = "Dark2") +
labs(x = "Gross living area",
y = "Sale Price (log)",
color = NULL)
#| label: Partial dependence profiles for the random forest model focusing on building types and gross living area using facets
as_tibble(pdp_liv$agr_profiles) |>
mutate(Bldg_Type = stringr::str_remove(`_label_`, "random_forest_")) |>
ggplot(aes(`_x_`, `_yhat_`, color = Bldg_Type)) +
geom_line(data = as_tibble(pdp_liv$cp_profiles),
aes(x = Gr_Liv_Area, group = `_ids_`),
linewidth = 0.5, alpha = 0.1, color = "gray50") +
geom_line(linewidth = 1.2, alpha = 0.8, show.legend = FALSE) +
scale_x_log10() +
facet_wrap(~Bldg_Type) +
scale_color_brewer(palette = "Dark2") +
labs(x = "Gross living area",
y = "Sale Price (log)",
color = NULL)
#| label: creating a model-agnostic explainer for bean classification model and computing global model explanations
set.seed(1807)
vip_beans <-
explain_tidymodels(
rda_wflow_fit,
data = bean_train |> select(-class),
y = bean_train$class,
label = "RDA",
verbose = FALSE
) |>
model_parts()
#| label: visualizing Global explainer for the regularized discriminant analysis model on the beans data
ggplot_imp(vip_beans)
